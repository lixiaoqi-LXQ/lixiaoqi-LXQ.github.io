**R1**

主机和端系统可以看作同一事物，细微的差别在于，端系统是一个抽象的概念，主机是实例。常见的端系统有PC、手机、web服务器、智能家具等等。

---

**R9**

| 接入网技术   | 传输速率范围                     | 共享/专用 |
| ------- | -------------------------- | ----- |
| 拨号调制解调器 | 56kbps                     | 专用    |
| HFC     | 42.8Mbps下行速率、30.7 Mbps上行速率 | 共享    |
| DSL     | 24 Mbps下行速率、2.5 Mbps上行速率   | 专用    |
| FTTH    | 可高达千兆每秒                    | 专用    |

---

**R11**

$\frac L {R_1}+\frac L {R_2}$

---

**R12**

与分组交换相比，电路交换具有更强的专用性、稳定性。在电路交换中，FDM需要分离不同频段的信号，实现起来比TDM复杂。

---

**R13**

1. 使用电路交换，需要预留两条1Mbps的链路，所以只能支持两个用户

2. 如果使用分组交换：
   
    - 当2个用户同时在线时，最高负载量在2Mbps，在链路速率之内，分组可以被及时转发出去，所以基本没有排队时延
   
    - 当3个用户同时在线时，可能存在三者同时传输的情况，此时链路负载为3Mbps，超出链路速率，分组会被阻塞，这种情况下存在时延
   
    - 20%
   
    - 三个用户同时传输的概率：$(20\%)^3=0.8\%$，因此队列增长的时间比率为$0.8\%$

---

**R18**

$$
T_{prop}=\frac{2500km}{2.5\times10^8m/s}=10ms \\
$$

所以用时10ms

一般情况：$T=\frac d s$，传输速率决定的是泵出比特的速度，传播时延与之无关。

---

**R19**

1. 吞吐量受限于瓶颈链路的速率，故吞吐量是500kbps

2. $\frac{4MB}{500kbps}=\frac{4\times10^6\times8bits}{500\times10^3bps}=64s$

3. 吞吐量：100kbps。传输用时：$5\times64s=320s$

---

**R23**

因特网协议栈，自顶向下：应用层、传输层、网络层、链路层、物理层。

- 应用层：在网络应用进程之间传输报文(message)

- 传输层：在应用程序端点间传送应用层报文，产生传输层的分组，报文段(segment)

- 网络层：将数据报(datagram)从一个主机转移到另一台主机

- 链路层：将数据以帧(frame)为单位传递给下一个节点

- 物理层：将比特从一个节点转移到下一个节点

---

**R25**

Router处理层次：物理层、链路层、网络层

Switch处理层次：物理层、链路层

主机处理层次：应用层、传输层、网络层、链路层、物理层

---

**P2**

第一段链路发送前$P-1$个用时：$(P-1)\frac L R$

最后一个分组走过全部链路用时：$N\frac L R$

因此端到端时延：$(N+P-1)\frac L R$

---

**P3**

1. 由于数据产生比较稳定，生成频率高，所以符合电路交换的特点，使用电路交换可以提供优秀的稳定性。此外长期使用也不会担心建立、销毁电路带来的时间开销。

2. 数据传输速率小于链路最大吞吐量，所以不会有阻塞发生，因此不需要拥塞控制。

---

**P6**

1. $d_{prop}=\frac m s$

2. $d_{trans}=\frac L R$

3. $d=d_{prop}+d_{trans}=\frac m s +\frac L R$

4. 经过时间$d_{trans}$，分组刚刚被完全传输，即最后1个bit在链路起点处

5. 仍在链路中传输

6. 已经被接收端接收

7. $$
   d_{prop}=d_{trans}\\
\frac m s = \frac L R\\
m = \frac {Ls} R \approx 535.7km
   $$

---

**P14**

1. $d=d_{queue} + d_{trans}=\frac{IL}{R(1-I)}+\frac L R=\frac L {(1-I)R}$

2. 由(1)：$d=\frac L R\cdot\frac 1 {1-a\cdot\frac L R}=\frac 1 a(\frac 1 {1-a\cdot\frac L R} - 1)$
   
   ![](/home/lixiaoqi/.config/marktext/images/2022-09-06-23-49-53-image.png)

---

**P22**

被成功接收，则N条链路都不丢包，概率为$(1-p)^N$

记$q=(1-p)^N$，X为重传次数，则$X+1\sim G(q)$

$E[X+1]=E X+1=\frac 1 q=\frac 1 {(1-p)^N}$

故重传次数的期望值是$\frac 1 {(1-p)^N}-1$

---

**P25**

1. $t_{prop}=\frac{20000km}{2.5\times10^8m/s}=80ms$
   
   $R\cdot t_{prop}=0.16MB$

2. 在第一个比特刚好传播到主机B时，耗时$t_{prop}$，此时一共传输了$R\cdot t_{prop}$个比特，即$0.16MB<0.8MB$，即链路上具有的比特最大数量最大值是$0.16MB$

3. 链路满负荷时，整条链路上具有的比特最大值。

4. 满负荷时，比特的平均宽度是：$\frac{20000km}{0.16MB}=125m/bit$，大于足球场的标准长度。

5. $\frac s R$

---

**P27**

1. $R\cdot t_{prop}=1Gbps\times80ms=80MB$

2. $0.8MB$

3. $0.25m$

---

**P31**

| L/bit         | L'/bit    | R/Mbps |
| ------------- | --------- | ------ |
| $8\times10^6$ | $10\ 000$ | 2      |

| N   | P   |
| --- | --- |
| 3   | 800 |

1. 从源主机到第一台分组交换机耗时：$\frac L R=4s$
   
   端到端延时：$N\frac L R=12s$

2. 从源主机移动一个分组到第一台分组交换机耗时：$\frac {L'}R=5ms$
   
   从第一台交换机发送第一个分组到第二台交换机耗时：$5ms$
   
   从源主机发送第二个分组到第一台交换机耗时：$5ms$
   
   $10ms$后第二个分组可以被第一台交换机全部收到

3. 传输文件总用时：$(N+P-1)\frac {L'} R=4.01s$
   
   可见分段传输产生的时延要显著小于不分段传输。
   
   细粒度的分段相当于提高了数据传输的并行度。不分段时，其他几段链路处于空闲状态，而分段粒度足够细时，每条链路都在传输，相当于有N倍的并行度。对于本例，有三段链路，所以分段时延接近于不分段的三分之一。

4.  - 分段使得提高了错误容忍度。假设不分段传输大文件，其中几个比特的错误就会导致整个文件重传，而分段传输则可以减少这种代价。
   
    - 分段还使得链路传输资源可以被公平地占用，避免特大文件阻塞许多小文件，造成其他用户/进程的不必要等待。

5.  - 将数据分段和合并的处理时延可能会比较大。
   
    - 伴随着封装分段的头部

---
