# HW2

#### R4

不同意，因为P2P文件共享中，一个用户既可能作为客户端从其他用户处下载文件，也可以作为服务器端为他人提供文件片段。

#### R5

主机地址(IP)+进程标识符(port number)

#### R6

UDP。因为UDP不需要TCP协议的三次握手，能够尽快收到响应。

#### R9

> 这里中文译本：强化UDP
> 
> 英文原版：*wants TCP to be enhanced*
> 
> 以英文版为准

SSL在应用层。

SSL的工作原理是：应用程序将明文传递给SSL套接字，SSL服务将其加密后传递给TCP套接字，经过网络传输，报文到达目标主机的TCP套接字，传递给SSL，解密后通过SSL套接字传递给接受进程。

因此程序研制者想利用SSL来强化TCP，需要向SSL发送明文数据，加密工作将有SSL服务完成。

#### P1

1. 错。根据HTTP协议，服务器在一次应答中只返回一个响应报文，用户需要根据页面中的链接再次请求对象。

2. 对。因为主机可能一致，就可以通过持续连接的HTTP连续发送。

3. 错。同1，每个TCP报文只包含至多一个HTTP对象。

4. 错。Date：首部行指示服务器产生并发送响应报文的日期与时间。

5. 错。如HEAD方法对应的响应报文实体体为空。

#### P5

1. 能。Date：Tue, 07 Mar 2008 12:39:45GMT

2. Last-Modified: Sat, 10 Dec2005 18:27:46 GMT

3. 3874

4. 前5个字节：`<!doc`
   
   同意持续连接

#### R13

请求对象的总响应时间由三个部分组成：

- 局域网时延

- 接入时延

- 因特网时延

在接入链路带宽较小时，会导致接入链路成为速度瓶颈，使得接入时延较大。

如果网络核心的某些因素(如网络拥挤、物理链路限制等)导致因特网时延比较大，也会使总响应时间很大。

加入Web缓存就使得命中的请求只在局域网内部传输，局域网的链路带宽通常不会成为瓶颈；另一方面，未命中的对象请求只占一部分，这样得到的总响应时间期望值会远远小于原值，同时有利于减轻互联网负担。

理论上，Web缓存器能减少用户请求的所有对象的时延。因为Web缓存器的存在使得网络流量下降，所以即使是对于未命中的情况，响应时延也会有所下降。

#### R16

```mermaid
flowchart LR
    A[User Agent for Alice]
    B[User Agent for Bob]
    M1[Mail Server 1]
    M2[Mail Server 2]
    A-->|HTTP|M1-->|SMTP|M2-->|POP3|B
```

#### P9

> 这里中文译本：命中率0.4
> 
> 英文原版：*miss rate is 0.4*
> 
> 以英文版为准

| L(MB) | a(个/秒) | R(Mbps) | 平均因特网时延(s) | 平均接入时延                         |
| ----- | ------ | ------- | ---------- | ------------------------------ |
| 0.85  | 16     | 15      | 3          | $\triangle/(1-\triangle\beta)$ |

$\triangle=L/R=\frac{0.85MB}{15Mbps}\approx0.567s$

$\beta=16$

所以平均接入时延是$\triangle/(1-\triangle\beta)=\frac{0.567}{1-0.567\times16}\approx0.607s$

因此总的平均响应时间为：$3s+0.607s=3.607s$

安装了Web缓存器后：

- 命中部分，$delay=0s$

- 未命中部分，重新计算平均接入时延
  
  $\triangle/(1-\triangle\beta')=\frac{0.567}{1-0.567\times16\times0.4}\approx0.089s$
  
  此时平均响应时间为：$3s+0.089s=3.089s$

故总的响应时间变为：$0s\times0.6+0.124s\times0.4\approx1.24s$

#### P10

因为是只有10m长的短链路，所以传播时延可以忽略不计，只考虑传输时延。

**持续连接**

- 第一次接收数据：$200bit/150bps\times3+10^5bit/150bps$

- 使用同一连接先后接收另外10个引用：$10\times(200bit/150bps+10^5bit/150bps)$

- 求和得到结果：$7350.7s$

**非持续连接**

- 第一次接收数据：$200bit/150bps\times3+10^5bit/150bps$

- 10个并发的过程(建立连接+控制报文+接收文件)，此时带宽被共享，只剩$15bps$
  
  $200bit/15bps\times3+10^5bit/15bps$

- 求和得到结果：$7377.3s$

综上分析可知：

1. 并行下载一来不削减链路负载，二来链路带宽被均匀共享，所以并没有意义。

2. 持续连接带来的收益主要是更少的连接建立时期的控制报文，但是由于此案例中，控制报文的长度和数据报文相比微不足道，所以持续连接并没有带来很大增益。

#### R19

#### R22

#### R23

#### P11

#### P22

#### R26

#### P23

#### P24
